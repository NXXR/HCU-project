{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Classifying Movie Reviews\n*A binary classification example*\n### Loading the Dataset\nLoad the dataset and keep the 10.000 most frequently occurring words.\nThe loaded data is split 50/50 into train data and test data.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "\r   8192/1641221 [..............................] - ETA: 34s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  40960/1641221 [..............................] - ETA: 13s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 106496/1641221 [\u003e.............................] - ETA: 7s ",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 245760/1641221 [\u003d\u003d\u003d\u003e..........................] - ETA: 3s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 507904/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1032192/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1646592/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 1us/step\n",
            "? this film was just brilliant casting location scenery story direction everyone\u0027s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy\u0027s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don\u0027t you think the whole story was so lovely because it was true and was someone\u0027s life after all that was shared with us all\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "from keras.datasets import imdb\n\n# load data and split into training and test (50/50)\n(train_data, train_labels), (test_data, test_labels) \u003d imdb.load_data(num_words\u003d10000)\n\n## decode and display single entry of dataset\n# get word -\u003e index mapping from dataset\nword_index \u003d imdb.get_word_index()\n# reverse to get index -\u003e word mapping\nreverse_word_index \u003d dict([(value, key) for (key, value) in word_index.items()])\n# decode review\ndecoded_review \u003d \" \".join(reverse_word_index.get(i - 3, \"?\") for i in train_data[0])\n#--- index offset because 0, 1, and 2 are reserved for \"padding\", \"start of sequence\" and \"unknown\"\nprint(decoded_review)"
    },
    {
      "cell_type": "markdown",
      "source": "### Prepare the Data\nOnly Tensors can be fed into a neural network, therefore two options:\n1. pad lists to same length and turn into tensor of shape (samples, word_indices) e.g. for *Embedding Layer*\n2. encode lists into vectors of size 10.000 e.g. for *Dense Layer*\n    - index list of [3, 5] turns into vector with all 0 except for position 3 \u0026 5",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": "import numpy as np\n\n# function to turn list of indices into vector with indices set to 1 (default 0)\ndef vectorize_sequences(sequences, dimension\u003d10000):\n    # create matrix of size: number of sequences (reviews) X dimension of sequence (10.000)\n    results \u003d np.zeros((len(sequences), dimension))\n    # set indices of sequence to 1\n    for i, seq in enumerate(sequences):\n        results[i, seq] \u003d 1\n    return results\n\n# vectorize training and test data\nx_train \u003d vectorize_sequences(train_data)\nx_test \u003d vectorize_sequences(test_data)\n\n# vectorize labels (already 1 \u003d positive / 0 \u003d negative)\ny_train \u003d np.asarray(train_labels).astype(\"float32\")\ny_test \u003d np.asarray(test_labels).astype(\"float32\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Building the Network\nThe network is proposed as:\n+ 2 intermediate layers (Dense) with 16 hidden units \u0026 relu activations\n+ 1 output layer (Dense) with 1 hidden unit \u0026 sigmoid activation",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\M.Zeumer\\Anaconda3\\envs\\HCU-project\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "from keras import models, layers\n\n# create sequential model to add layers\nmodel \u003d models.Sequential()\n# add intermediate layers\nmodel.add(layers.Dense(16, activation\u003d\"relu\", input_shape\u003d(10000,)))\nmodel.add(layers.Dense(16, activation\u003d\"relu\"))\n# add output layer\nmodel.add(layers.Dense(1, activation\u003d\"sigmoid\"))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}